{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1bf1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4fcccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#import config   ### just need to import config for config.py - if want to take specific method in config then use from config import \"name of method\"\n",
    "from utils.checkpoints import CheckpointIO\n",
    "from mesh_generate import generate \n",
    "#from training import training\n",
    "from torch.utils import data\n",
    "from models import OccupancyNetwork\n",
    "from data import dataset\n",
    "from tqdm import trange,tqdm\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as dist\n",
    "from utils.common import (\n",
    "    compute_iou, make_3d_grid\n",
    ")\n",
    "from utils import visualize as vis\n",
    "from collections import defaultdict\n",
    "from data import dataset\n",
    "from training import train\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92a6f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# print(numpy.get_include())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f194333",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"ocnet.yaml\"\n",
    "with open(path, 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Shorthands\n",
    "out_dir = \"out/onet\"\n",
    "backup_every = 100000\n",
    "#exit_after = args.exit_after  ### can check later if we really need the exit after\n",
    "\n",
    "model_selection_metric = \"iou\"\n",
    "# model_selection_sign = 1\n",
    "\n",
    "# Output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "776eb547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3932d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_remove_none(batch):\n",
    "    ''' Collater that puts each data field into a tensor with outer dimension\n",
    "        batch size.\n",
    "\n",
    "    Args:\n",
    "        batch: batch\n",
    "    '''\n",
    "\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return data.dataloader.default_collate(batch)\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    ''' Worker init function to ensure true randomness.\n",
    "    '''\n",
    "    random_data = os.urandom(4)\n",
    "    base_seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "    np.random.seed(base_seed + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71291e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(os.path.join(out_dir, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "797ba25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = dataset.get_dataset('train', cfg)\n",
    "val_dataset = dataset.get_dataset('val', cfg)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, num_workers=4, shuffle=True,\n",
    "    collate_fn=collate_remove_none,\n",
    "    worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=12, num_workers=4, shuffle=False,\n",
    "    collate_fn=collate_remove_none,\n",
    "    worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d0ea081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizations\n",
    "vis_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=10, shuffle=True,\n",
    "    collate_fn=collate_remove_none,\n",
    "    worker_init_fn=worker_init_fn)\n",
    "data_vis = next(iter(vis_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ab8ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model= OccupancyNetwork.OccupancyNetwork(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e7586b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from torchvision import models\n",
    "# from utils.common import normalize_imagenet\n",
    "# class Resnet18(nn.Module):\n",
    "#     r''' ResNet-18 encoder network for image input.\n",
    "#     Args:\n",
    "#         c_dim (int): output dimension of the latent embedding\n",
    "#         normalize (bool): whether the input images should be normalized\n",
    "#         use_linear (bool): whether a final linear layer should be used\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, c_dim=256, normalize=True, use_linear=True):\n",
    "#         super().__init__()\n",
    "#         self.normalize = normalize\n",
    "#         self.use_linear = use_linear\n",
    "#         self.features = models.resnet18(pretrained=True)\n",
    "#         self.features.fc = nn.Sequential()\n",
    "#         self.fc = nn.Linear(512, c_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = normalize_imagenet(x)\n",
    "#         net = self.features(x)\n",
    "#         out = self.fc(net)\n",
    "#         return out\n",
    "# x=Resnet18()\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "990f65ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchvision import models\n",
    "# class ResNetFeatures(nn.Module):\n",
    "#     def __init__(self, model=models.resnet18(pretrained=True)):\n",
    "#         super(ResNetFeatures, self).__init__()\n",
    "\n",
    "#         #self.out_channels = 512\n",
    "#         self.sequential = nn.Sequential(model.conv1,\n",
    "#                                   model.bn1,\n",
    "#                                   model.relu,\n",
    "#                                   model.maxpool,\n",
    "#                                   model.layer1,\n",
    "#                                   model.layer2,\n",
    "#                                   model.layer3,\n",
    "#                                   model.layer4)   # to get channels of 512 \n",
    "#         #print(\"sequential\", self.sequential)\n",
    "#     def forward(self, x):\n",
    "#         return self.sequential(x)\n",
    "    \n",
    "# def frozen_batch_norm(model):\n",
    "#     for name, module in model.named_modules():\n",
    "#         if name == 'bn1' :\n",
    "#             module.requires_grad_ = False\n",
    "#         if name == 'layer1' or name == 'layer2' or name == 'layer3' or name == 'layer4':\n",
    "#             for child_name, child_module in module.named_modules():\n",
    "#                 if (len(child_name) > 1) and child_name[2:4] == 'bn':\n",
    "#                     child_module.requires_grad_ = False\n",
    "#     return model\n",
    "\n",
    "# y=frozen_batch_norm(ResNetFeatures())   # so out put (bs,512,7,7)\n",
    "# # y(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8754b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class C_Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))  \n",
    "#         self.fc = nn.Linear(in_features=512, out_features=256, bias=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.avgpool(x) # (batch size, channels, 1, 1)\n",
    "#         x = torch.flatten(x, 1) #(batch size, channels)- flatten to force all the tensor here to 1D\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b6c8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.c_layer=C_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a0fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e678ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def forward(self, p, inputs): # p is pointloud (bs,2048,3)\n",
    "#     feature = self.encoder(inputs)   #(bs,512,7,7)\n",
    "#     c=CustomModel(feature) # (bs,256)\n",
    "#     p_r =decoder(feature,p,c)\n",
    "#     return p_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbde5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.feature_channels_change=nn.Conv2d(512,256,1,1)\n",
    "# self.fc_p1 = nn.Conv1d(3, 256, 1)\n",
    "# self.bn = CBatchNorm1d(c_dim, hidden_size)\n",
    "# self.fc_out = nn.Conv1d(hidden_size, 1, 1)\n",
    "# self.actvn = F.relu\n",
    "# self.before_last_layer=nn.Sequential(nn.Conv1d(512, 256, 1))\n",
    "# def fc_p(p_size,feature_size):\n",
    "#     return nn.Linear(p_size,feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1208dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decoder(self,feature,p,c):\n",
    "#     p_size=p.shape[3]\n",
    "#     feature_size=feature.shape[3]\n",
    "#     fc_p2=fc_p(p_size,feature_size)\n",
    "    \n",
    "#     feature=self.feature_channels_change(feature)  \n",
    "#     p = p.transpose(1, 2) #bs,3,2048\n",
    "#     p=self.fc_p1(p) # bs,256,2048\n",
    "#     p=fc_p2(p) #bs,256,7\n",
    "#     p=p.unsqueeze(-1).repeat(1, 1, 1, feature_size)# bs,256,7,7\n",
    "    \n",
    "#     feature=torch.cat((feature, p), dim=1) #bs,512,7,7\n",
    "    \n",
    "#     pos_embed = self.positional_embeddings(feature)  \n",
    "#     net=self.transformer(feature, self.query_embed.weight,pos_embed)[0] # out size =[2048, 512, 12]\n",
    "    \n",
    "#     net = self.before_last_layer(out).transpose(0,2)  #to create output [bs=12, 256, 2048]\n",
    "#     #print(\"type\",type(out),type(feature_c))\n",
    "#     out = self.fc_out(self.actvn(self.bn(net, c)))\n",
    "#     out = out.squeeze(1)\n",
    "#     p_r = dist.Bernoulli(logits=out)\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74fa3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize training\n",
    "npoints = 1000\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "trainer = train.Train(                         ## set the trainig for training\n",
    "    model, optimizer,\n",
    "    device=device, input_type=\"img\",\n",
    "    vis_dir=\"out/img/onet/vis\", threshold=0.2,\n",
    "    eval_sample=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e3de7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best validation metric (iou): -inf\n"
     ]
    }
   ],
   "source": [
    "## all here to load check point and get info from the check point\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)  ##save check poins\n",
    "try:                                                            ##here to load checkpoint to cotinue to train i guess\n",
    "    load_dict = checkpoint_io.load('model.pt')         ## so here model saved as .pt not .ckpt\n",
    "except FileExistsError:\n",
    "    load_dict = dict()\n",
    "epoch_it = load_dict.get('epoch_it', -1)\n",
    "it = load_dict.get('it', -1)\n",
    "metric_val_best = load_dict.get(\n",
    "    'loss_val_best', -np.inf)\n",
    "\n",
    "\n",
    "print('Current best validation metric (%s): %.8f'\n",
    "      % (model_selection_metric, metric_val_best))   ## model_selection_metric here is IoU metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6cf1faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OccupancyNetwork(\n",
      "  (decoder): DecoderCBatchNorm(\n",
      "    (fc_p): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
      "    (block0): CResnetBlockConv1d(\n",
      "      (bn_0): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (bn_1): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (fc_0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (fc_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (actvn): ReLU()\n",
      "    )\n",
      "    (block1): CResnetBlockConv1d(\n",
      "      (bn_0): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (bn_1): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (fc_0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (fc_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (actvn): ReLU()\n",
      "    )\n",
      "    (block2): CResnetBlockConv1d(\n",
      "      (bn_0): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (bn_1): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (fc_0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (fc_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (actvn): ReLU()\n",
      "    )\n",
      "    (block3): CResnetBlockConv1d(\n",
      "      (bn_0): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (bn_1): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (fc_0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (fc_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (actvn): ReLU()\n",
      "    )\n",
      "    (block4): CResnetBlockConv1d(\n",
      "      (bn_0): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (bn_1): CBatchNorm1d(\n",
      "        (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (fc_0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (fc_1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (actvn): ReLU()\n",
      "    )\n",
      "    (bn): CBatchNorm1d(\n",
      "      (conv_gamma): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (conv_beta): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    )\n",
      "    (fc_out): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (encoder): Resnet18(\n",
      "    (features): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Sequential()\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 13414465\n"
     ]
    }
   ],
   "source": [
    "###TODO: reintroduce or remove scheduler? - not delete here\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4000,\n",
    "#                                       gamma=0.1, last_epoch=epoch_it)\n",
    "\n",
    "\n",
    "# Shorthands\n",
    "print_every = 10\n",
    "#checkpoint_every = cfg['training']['checkpoint_every']\n",
    "checkpoint_every =50\n",
    "#validate_every = cfg['training']['validate_every']\n",
    "validate_every = 50\n",
    "# visualize_every = cfg['training']['visualize_every']\n",
    "visualize_every = 50\n",
    "# Print model                                                   \n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "print(model)\n",
    "print('Total number of parameters: %d' % nparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "899c99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90f3c138",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03] it=000, loss=1817.8379\n",
      "Visualizing\n",
      "p_r: Bernoulli(logits: torch.Size([10, 32768]))\n",
      "p_r.probs torch.Size([10, 32768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [01:24<00:00,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Backup checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [02:25<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metric (iou): 0.0480\n",
      "New best model (loss 0.0480)\n",
      "[Epoch 03] it=010, loss=468.8732\n",
      "[Epoch 03] it=020, loss=367.9352\n",
      "[Epoch 03] it=030, loss=287.4140\n",
      "[Epoch 03] it=040, loss=332.4796\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m epoch_it \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      7\u001b[0m     it \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_step(batch)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-T2s4-u2a-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-T2s4-u2a-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1186\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-T2s4-u2a-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1154\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry-T2s4-u2a-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_it=2\n",
    "while True:\n",
    "    epoch_it += 1\n",
    "    #scheduler.step()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        it += 1\n",
    "        loss = trainer.train_step(batch)\n",
    "        logger.add_scalar('train/loss', loss, it)\n",
    "\n",
    "        # Print output\n",
    "        if print_every > 0 and (it % print_every) == 0:\n",
    "            print('[Epoch %02d] it=%03d, loss=%.4f'\n",
    "                  % (epoch_it, it, loss))\n",
    "\n",
    "        # Visualize output\n",
    "        if visualize_every > 0 and (it % visualize_every) == 0:\n",
    "            print('Visualizing')\n",
    "            trainer.visualize(data_vis)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (checkpoint_every > 0 and (it % checkpoint_every) == 0):\n",
    "            print('Saving checkpoint')\n",
    "            checkpoint_io.save('model.pt', epoch_it=epoch_it, it=it,\n",
    "                               loss_val_best=metric_val_best)\n",
    "\n",
    "        # Backup if necessary\n",
    "        if (backup_every > 0 and (it % backup_every) == 0):\n",
    "            print('Backup checkpoint')\n",
    "            checkpoint_io.save('model_%d.pt' % it, epoch_it=epoch_it, it=it,\n",
    "                               loss_val_best=metric_val_best)\n",
    "        # Run validation\n",
    "        if validate_every > 0 and (it % validate_every) == 0:\n",
    "            eval_dict = trainer.evaluate(val_loader)\n",
    "            metric_val = eval_dict[model_selection_metric]\n",
    "            print('Validation metric (%s): %.4f'\n",
    "                  % (model_selection_metric, metric_val))\n",
    "\n",
    "            for k, v in eval_dict.items():\n",
    "                logger.add_scalar('val/%s' % k, v, it)\n",
    "\n",
    "            if (metric_val - metric_val_best) > 0:\n",
    "                metric_val_best = metric_val\n",
    "                print('New best model (loss %.4f)' % metric_val_best)\n",
    "                checkpoint_io.save('model_best.pt', epoch_it=epoch_it, it=it,\n",
    "                                   loss_val_best=metric_val_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63f494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.p0_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d39efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./out/onet/logs --port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
