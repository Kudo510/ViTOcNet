{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "SaXjOW1Cod2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21195,
     "status": "ok",
     "timestamp": 1688475430575,
     "user": {
      "displayName": "Kaan Özgen",
      "userId": "00027637599763072730"
     },
     "user_tz": -120
    },
    "id": "SaXjOW1Cod2b",
    "outputId": "a3b15511-387c-4a71-f68e-bdc6e3653a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PPz06RkwPOzo",
   "metadata": {
    "id": "PPz06RkwPOzo"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6M7kJa0twHz5",
   "metadata": {
    "id": "6M7kJa0twHz5"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6EtKKFxAyqWX",
   "metadata": {
    "id": "6EtKKFxAyqWX"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/sample_code sample_code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROLDOhPDo13M",
   "metadata": {
    "id": "ROLDOhPDo13M"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from dataset import load_train_data, load_val_data\n",
    "import os\n",
    "os.chdir('/content/sample_code/vit')\n",
    "with ZipFile('tiny-imagenet-200.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()\n",
    "\n",
    "os.chdir('/content/sample_code/vit/tiny-imagenet-200')\n",
    "!mv * ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JWg_Z8IGtPvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454647,
     "status": "ok",
     "timestamp": 1688087062130,
     "user": {
      "displayName": "Kaan Özgen",
      "userId": "00027637599763072730"
     },
     "user_tz": -120
    },
    "id": "JWg_Z8IGtPvK",
    "outputId": "bf2d199c-ba46-4f10-be73-fc58e4d42a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 3, 64, 64]) torch.Size([100000])\n",
      "torch.Size([10000, 3, 64, 64]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Takes approximately 8 minutes. From images, creates pickle dataset for fast reading\n",
    "os.chdir('/content/sample_code/vit')\n",
    "!python /content/sample_code/vit/fileio.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3IuS4fMWB26D",
   "metadata": {
    "id": "3IuS4fMWB26D"
   },
   "outputs": [],
   "source": [
    "from math import e\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook, tqdm, trange\n",
    "from importlib import reload\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "sys.path.insert(0, '/content/sample_code/vit/models/')\n",
    "from vit_model import ViT\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def main(config):\n",
    "\n",
    "    # Loading data\n",
    "    transform = ToTensor()\n",
    "\n",
    "    img_size = config['img_size']\n",
    "    randaug_magnitude = 0\n",
    "    batch_size = config['batch_size']\n",
    "    input_image_channels = config['input_image_channels']\n",
    "    if config['dataset'] == 'MNIST':\n",
    "      train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
    "      test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "      train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "      val_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)\n",
    "    elif config['dataset'] == 'TINY_IMAGENET':\n",
    "      train_loader = load_train_data(img_size, randaug_magnitude, batch_size)\n",
    "      val_loader = load_val_data(img_size, batch_size)\n",
    "    else:\n",
    "      raise Exception('Wrong Dataset name!')\n",
    "\n",
    "\n",
    "    # Defining model and training options\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "    model = ViT((input_image_channels, img_size, img_size),\n",
    "                                                          n_patches=config['n_patches'],\n",
    "                                                          n_blocks=config['n_blocks'],\n",
    "                                                          hidden_d=config['hidden_d'],\n",
    "                                                          n_heads=config['n_heads'],\n",
    "                                                          out_d=config['out_d'],\n",
    "                                                          mlp_ratio=config['mlp_ratio']).to(device)\n",
    "    print(f'# of Parameters in Model: {sum(p.numel() for p in model.parameters())}')\n",
    "    N_EPOCHS = config['N_EPOCHS']\n",
    "    LR = config['LR']\n",
    "    weight_decay = config['weight_decay']\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", position=0, leave=True)):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            batch_loss = loss.detach().cpu().item() / len(train_loader)\n",
    "            train_loss += batch_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx + 1) % config['print_every_nth_batch'] == 0:  # print every 50th batch\n",
    "                print(f\"{batch_idx + 1}th Batch loss: {batch_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Test loop\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        for batch in tqdm(val_loader, desc=\"Testing\"):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss += loss.detach().cpu().item() / len(val_loader)\n",
    "\n",
    "            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "            total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-GIC9SqqIydn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046220,
     "status": "ok",
     "timestamp": 1688091062037,
     "user": {
      "displayName": "Kaan Özgen",
      "userId": "00027637599763072730"
     },
     "user_tz": -120
    },
    "id": "-GIC9SqqIydn",
    "outputId": "e5b9fa76-3317-416a-a831-4df141dc0e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (Tesla T4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  11%|█         | 50/469 [00:36<05:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  21%|██▏       | 100/469 [01:11<04:06,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  32%|███▏      | 150/469 [01:47<03:40,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150 loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  43%|████▎     | 200/469 [02:23<03:46,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  53%|█████▎    | 250/469 [02:59<02:24,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  64%|██████▍   | 300/469 [03:35<01:56,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  75%|███████▍  | 350/469 [04:11<01:38,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350 loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  85%|████████▌ | 400/469 [04:48<00:50,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training:  96%|█████████▌| 450/469 [05:24<00:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450 loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training: 100%|██████████| 469/469 [05:39<00:00,  1.38it/s]\n",
      "Training:  33%|███▎      | 1/3 [05:39<11:18, 339.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 2.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  11%|█         | 50/469 [00:35<05:56,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  21%|██▏       | 100/469 [01:11<04:09,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  32%|███▏      | 150/469 [01:47<03:39,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150 loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  43%|████▎     | 200/469 [02:22<03:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  53%|█████▎    | 250/469 [02:57<02:25,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  64%|██████▍   | 300/469 [03:34<01:59,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  75%|███████▍  | 350/469 [04:12<01:38,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350 loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  85%|████████▌ | 400/469 [04:47<00:45,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training:  96%|█████████▌| 450/469 [05:23<00:13,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450 loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training: 100%|██████████| 469/469 [05:37<00:00,  1.39it/s]\n",
      "Training:  67%|██████▋   | 2/3 [11:16<05:37, 337.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 1.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  11%|█         | 50/469 [00:34<04:36,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  21%|██▏       | 100/469 [01:11<04:02,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  32%|███▏      | 150/469 [01:47<04:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150 loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  43%|████▎     | 200/469 [02:22<02:53,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  53%|█████▎    | 250/469 [02:58<02:26,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  64%|██████▍   | 300/469 [03:34<02:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  75%|███████▍  | 350/469 [04:10<01:20,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350 loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  85%|████████▌ | 400/469 [04:46<00:53,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training:  96%|█████████▌| 450/469 [05:22<00:12,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450 loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training: 100%|██████████| 469/469 [05:35<00:00,  1.40it/s]\n",
      "Training: 100%|██████████| 3/3 [16:51<00:00, 337.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 1.7809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 79/79 [00:34<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.76\n",
      "Test accuracy: 70.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "config = {\n",
    "    'img_size' : 224,\n",
    "    'batch_size': 16,\n",
    "    'input_image_channels': 3,\n",
    "    'n_patches': 7,\n",
    "    'n_blocks': 12,\n",
    "    'hidden_d': 768,\n",
    "    'n_heads': 12,\n",
    "    'out_d': 200,\n",
    "    'N_EPOCHS' : 5,\n",
    "    'LR' : 0.001,\n",
    "    'weight_decay': 0.05,\n",
    "    'dataset': 'TINY_IMAGENET',\n",
    "    'print_every_nth_batch': 50,\n",
    "    'mlp_ratio': 4\n",
    "}\n",
    "\"\"\"\n",
    "config = {\n",
    "    'img_size' : 28,\n",
    "    'batch_size': 128,\n",
    "    'input_image_channels': 1,\n",
    "    'n_patches': 7,\n",
    "    'n_blocks': 2,\n",
    "    'hidden_d': 8,\n",
    "    'n_heads': 2,\n",
    "    'out_d': 10,\n",
    "    'N_EPOCHS' : 3,\n",
    "    'LR' : 0.005,\n",
    "    'weight_decay': 0.05,\n",
    "    'dataset': 'MNIST',\n",
    "    'print_every_nth_batch': 50,\n",
    "    'mlp_ratio': 4\n",
    "}\n",
    "main(config)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
